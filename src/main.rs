extern crate rand;
extern crate rayon;
extern crate rustc_serialize;
extern crate docopt;
extern crate tabwriter;

use std::io::BufRead;
use std::io::BufReader;
use std::fs::File;
use std::process::exit;
use std::slice::{Chunks,Iter};
use std::iter::Zip;
use rand::Rng;
use rand::Open01;
use rayon::par_iter::{IntoParallelIterator, ParallelIterator};
use docopt::Docopt;
use std::io::Write;
use tabwriter::TabWriter;

struct DataSet {
    counts: Vec<u64>,
    sequences: Vec<u8>,
    key_len: usize,
    mask: Vec<bool>,
}

impl DataSet {
    fn iter(&self) -> Zip<Iter<u64>,Chunks<u8>> {
        self.counts.iter().zip(self.sequences.chunks(self.key_len))
    }
}

fn key_mask(key: &str) -> Vec<bool> {
    let mut mask = Vec::new();

    for base in key.chars() {
        match base {
            'A' | 'C' | 'G' | 'T' => mask.push(true),
            'N' => mask.push(false),
            _ => {
                println!("Unknown base '{}'", base);
                exit(1);
            }
        }
    }

    mask
}

fn decode_key_into(key: &str, storage: &mut Vec<u8>, len: &mut usize) {
    if *len > 0 && key.len() != *len {
        
    }
    
    let mut active_len = 0;
    for base in key.chars() {
        match base {
            'A' => { active_len += 1; storage.push(0) },
            'C' => { active_len += 1; storage.push(1) },
            'G' => { active_len += 1; storage.push(2) },
            'T' => { active_len += 1; storage.push(3) },
            'N' => {}, // ignore unused bases
            _ => {
                println!("Unknown base '{}'", base);
                exit(1);
            }
        }
    }

    if *len == 0 {
        *len = active_len;
    } else if *len != active_len {
        println!("Invalid data file format: expected all keys to have the same length ({}): {} has length {}.", *len, key, active_len);
        exit(1);
    }
}

/// Load data table (output from seqOutBias)
/// Data table in the format outputed by "seqOutBias table ..." command 
fn load_data<R: BufRead>(source: R) -> DataSet {
    let mut counts = Vec::new();
    let mut sequences = Vec::new();
    let mut key_len = 0;
    let mut mask = None;

    for line in source.lines() {
        if let Ok(line) = line {
            if line == "" { break; }
            if line.starts_with('#') { continue; }

            let parts: Vec<&str> = line.split('\t').collect();

            if parts.len() != 6 {
                println!("Invalid data file format: expected 6 columns, found {} in line '{}'.", parts.len(), line);
                exit(1);
            }

            // get counts
            let bam_plus: u64 = parts[4].parse().unwrap();
            let bam_minus: u64 = parts[5].parse().unwrap();
            let total = bam_plus + bam_minus;

            // filter out sequences with zero occurrences
            if total > 0 {
                counts.push(total);

                // decode key
                if key_len == 0 { mask = Some(key_mask(parts[1])) }
                decode_key_into(parts[1], &mut sequences, &mut key_len);
            }
        } else {
            println!("Unexpected error reading data file.");
            exit(2);
        }
    }

    // free any excess allocation
    sequences.shrink_to_fit();

    DataSet {
        counts: counts,
        sequences: sequences,
        key_len: key_len,
        mask: mask.unwrap(),
    }
}

#[derive(Debug)]
struct ParamSet {
    /// gamma_i = P(z_i = "forward"), i.e., probability that sequence 'i' is generated by a forward aligned matrix
    gamma: Vec<f64>, 
    /// position weight matrix, i.e., generator probabilities for each base for each sequence position
    alpha: Vec<[f64;4]>, 
}

impl ParamSet {
    fn new(seq_len: usize, seq_count: usize) -> ParamSet {
        let mut rng = rand::thread_rng();

        // generate random values for gamma
        let gamma = (0..seq_count).map(|_| {
            let Open01(val) = rng.gen::<Open01<f64>>();
            val 
        }).collect();
        let mut alpha = Vec::new();

        // TODO: check if it's better to derive the values from data given gamma
        for _ in 0..seq_len {
            // generate random values for alpha_i
            let aux: Vec<u32> = (0..4).map(|_| rng.gen()).collect();
            let total = (&aux).iter().fold(0u64, |acc, &x| acc + x as u64);

            let mut alpha_i = [0f64;4]; 
            for (j, &value) in (0..4).zip(aux.iter()) {
                alpha_i[j] = (value as f64) / (total as f64);
            }

            //
            alpha.push(alpha_i);
        }

        ParamSet {
            gamma: gamma,
            alpha: alpha,
        }
    }

    /// Orient matrix given gamma
    ///
    /// Make it so that the majority of the sequences correspond to the forward orientation.
    fn reorient(&mut self) {
        let count_fwd = self.gamma.iter().fold(0, |acc, &x| if x >= 0.5 { acc + 1} else { acc });
        if self.gamma.len() - count_fwd > count_fwd {
            // need to reorient dataset
            // 1. flip gamma
            for gamma_i in &mut self.gamma {
                *gamma_i = 1.0 - *gamma_i;
            }
            // 2. flip alpha
            self.alpha.reverse();
            for alpha_j in &mut self.alpha {
                alpha_j.reverse();
            }

        }
    }
}

/// computes P(X | Z = fwd) and P(X | Z = rev)
fn sequence_probability(alpha: &Vec<[f64;4]>, sequence: &[u8]) -> (f64,f64) {
    let len = sequence.len();

    // forward
    let prob_fwd = sequence.iter().zip(0..len).fold(1f64, |acc, (&base, pos)| acc * alpha[pos][base as usize]);

    // reverse
    let prob_rev = sequence.iter().zip(0..len).fold(1f64, |acc, (&base, pos)| acc * alpha[len - pos - 1][3 - base as usize]);
    
    (prob_fwd, prob_rev)
}

fn log_likelihood(data: &DataSet, params: &ParamSet) -> f64 {
    let mut loglik = 0.0;
    for (&gamma, (&count, sequence)) in (&params.gamma).iter().zip(data.iter()) {
        let (prob_fwd, prob_rev) = sequence_probability(&params.alpha, sequence);
        
        // P(X) = sum_z P(X | Z = z)P(Z = z)
        let prob_z = gamma;
        let prob_x_i = prob_fwd * prob_z + prob_rev * (1.0 - prob_z);

        loglik = loglik + count as f64 * prob_x_i.ln();
    }
    loglik
}

fn sufsstats_to_probs(sstats: &mut [f64], pseudo_count: f64, probs: &mut [f64]) {
    let total = sstats.iter().fold(0., |acc, x| acc + x + pseudo_count);

    for (a,p) in sstats.iter().zip(probs.iter_mut()) {
        *p = (*a + pseudo_count) / total;
    }
}

fn expectation_maximization(data: &DataSet, params: &mut ParamSet, tolerance: f64, prefix: &str, verbose: bool) -> f64 {
    #![allow(non_snake_case)]

    let len = params.gamma.len();
    let a_len = params.alpha.len();
    let mut cur_loglik = log_likelihood(data, params);
    if verbose {
        println!("{}I: {:.5}", prefix, cur_loglik);
    }

    // sufficient statistics for alpha
    let mut sufstats: Vec<[f64;4]> = Vec::new();
    for _ in 0..params.alpha.len() {
        sufstats.push([0.0, 0.0, 0.0, 0.0]);
    }

    loop {
        // compute sufficient statistics
        for Aj in sufstats.iter_mut() {
            for Ajk in Aj.iter_mut() {
                *Ajk = 0.0;
            }
        }

        for (i, (&count, sequence)) in (0..len).zip(data.iter()) {
            let prob_z = params.gamma[i];
            let (prob_fwd, prob_rev) = sequence_probability(&params.alpha, sequence);
            let post_zi_fwd = (prob_fwd * prob_z) / (prob_fwd * prob_z + prob_rev * (1.0 - prob_z));

            // update gamma_i
            params.gamma[i] = post_zi_fwd;

            // accum Ajk
            for (j, Aj) in (0..a_len).zip(sufstats.iter_mut()) {
                let xi_fwd = sequence[j] as usize;
                let xi_rev = 3 - sequence[a_len - j - 1] as usize;

                Aj[xi_fwd] += count as f64 * post_zi_fwd;
                Aj[xi_rev] += count as f64 * (1.0 - post_zi_fwd); 
            }
        }

        // update alpha
        for (alpha_j, Aj) in params.alpha.iter_mut().zip(sufstats.iter_mut()) {
            sufsstats_to_probs(Aj, 0.1, alpha_j);
        }

        // compute new log-likelihood
        let next_loglik = log_likelihood(data, params);

        // stop condition
        if (next_loglik - cur_loglik).abs() < tolerance {
            cur_loglik = next_loglik;
            break;
        }
        cur_loglik = next_loglik;
        if verbose {
            println!("{}.: {:.5}", prefix, cur_loglik);
        }
    }

    // reorient to favor forward PWM
    params.reorient();

    //
    cur_loglik
}

fn max_base(probs: &[f64]) -> char {
    let mut idx = 0;
    let mut max_prob = probs[0]; 
    for (i, &val) in probs.iter().enumerate() {
        if val > max_prob {
            max_prob = val;
            idx = i;
        }
    }

    match idx {
        0 => 'A',
        1 => 'C',
        2 => 'G',
        3 => 'T',
        _ => 'N', // should never happen ...
    }
}

fn simple_pwm(data: &DataSet) -> Vec<[f64;4]> {
    let mut acc: Vec<[f64;4]> = Vec::new();
    let mut prob: Vec<[f64;4]> = Vec::new();

    for _ in 0..data.key_len {
        acc.push([0.0, 0.0, 0.0, 0.0]);
        prob.push([0.0, 0.0, 0.0, 0.0]);
    }

    for (&count, sequence) in data.iter() {
        for (col, &base) in acc.iter_mut().zip(sequence.iter()) {
            col[base as usize] += count as f64;
        }
    }

    for (prob_j, acc_j) in prob.iter_mut().zip(acc.iter_mut()) {
        sufsstats_to_probs(acc_j, 0., prob_j);
    }

    prob
}

fn print_pwm(pwm: &Vec<[f64;4]>) {
    let ic = pwm_to_ic(pwm);
    println!("    P(A)   P(C)   P(G)   P(T)   IC");
    for (pwm_j, &ic) in pwm.iter().zip(ic.iter()) {
        println!("{} {:.4} {:.4} {:.4} {:.4} {:.2}", max_base(pwm_j), pwm_j[0], pwm_j[1], pwm_j[2], pwm_j[3], ic);
    }
}

fn pwm_to_ic(pwm: &Vec<[f64;4]>) -> Vec<f64> {
    pwm.into_iter().map(|col| {
        col.iter().fold(2., |acc, &x| if x > 0. { acc + x * x.log2()} else { acc })
    }).collect()
}

fn pwm_to_cutmask(pwm: &Vec<[f64;4]>, source_mask: &Vec<bool>, thresh: f64) -> String {
    let ic = pwm_to_ic(pwm);
    let mut i = 0;
    let mut result = String::new();

    for &flag in source_mask {
        if flag {
            if ic[i] >= thresh {
                result.push('N');
            } else {
                result.push('X');
            }
            i += 1;
        } else {
            result.push('X');
        }
    }

    result
}

fn mirror_merged_cutmask(mask: &str) -> String {
    let mut result = String::new();

    // a position is used if it is 'unmasked' in either the source mask or it's mirror
    for (c, r) in mask.chars().zip(mask.chars().rev()) {
        if c == 'N' || r == 'N' {
            result.push('N'); // unmasked position
        } else {
            result.push('X'); // masked position
        }
    }

    result
}

/// Print a table of cutmasks for possible Information Content thresholds
fn print_cutmask_table(pwm: &Vec<[f64;4]>, source_mask: &Vec<bool>) {
    let ic_keys = {
        let mut ic = pwm_to_ic(pwm);
        ic.sort_by(|a, b| b.partial_cmp(a).unwrap()); // reverse sorting
        ic.dedup();
        ic
    };

    let mut tw = TabWriter::new(vec![]).padding(1);


    write!(&mut tw, "IC\tfwd_mask\tmerged_mask\n").unwrap();
    for thresh in ic_keys {
        let cutmask = pwm_to_cutmask(pwm, source_mask, thresh);
        let m_cutmask = mirror_merged_cutmask(&cutmask);
        write!(&mut tw, "{:.3}\t{}\t{}\n", thresh, cutmask, m_cutmask).unwrap();
    }

    tw.flush().unwrap();
    let written = String::from_utf8(tw.into_inner().unwrap()).unwrap();

    print!("{}", written);
}

struct EMResult {
    params: ParamSet,
    loglik: f64,
}

// main usage and arguments
const USAGE: &'static str = "
Cutmask EM

Usage:
  cutmask_em [options] <counts-file>
  cutmask_em (-h | --help)
  cutmask_em --version

Options:
  -h --help       Show this screen.
  --version       Show version.
  --verbose       Show intermediate results.
  --runs=<n>      Number of randomized EM starts [default: 5].
";

#[derive(Debug, RustcDecodable)]
struct Args {
    arg_counts_file: String,
    flag_runs: u8,
    flag_version: bool,
    flag_verbose: bool,
}


fn main() {
    // Parse command line arguments
    let args: Args = Docopt::new(USAGE)
                            .and_then(|d| d.decode())
                            .unwrap_or_else(|e| e.exit());

    if args.flag_version {
        println!("Cutmask EM, v{}.{}.{}", 
            env!( "CARGO_PKG_VERSION_MAJOR" ),
            env!( "CARGO_PKG_VERSION_MINOR" ),
            env!( "CARGO_PKG_VERSION_PATCH" ) );
        return;
    }

    if args.flag_verbose {
        println!("Loading data from {}", args.arg_counts_file);
        println!("");
    }

    let file = File::open(args.arg_counts_file).unwrap();
    let reader = BufReader::new(file);
    let data = load_data(reader);

    // only run simple PWM on verbose mode
    if args.flag_verbose {
        let simple = simple_pwm(&data); 
        println!("simple pwm:");
        print_pwm(&simple);
        print_cutmask_table(&simple, &data.mask);
        println!("");
    }

    if args.flag_verbose {
        println!("Running EM");
    }
    // do multiple EM runs with random starting points to ensure we find a good result
    let aux = args.flag_verbose;
    let res = (0u8..args.flag_runs).into_par_iter()
          .map(|rep| {
              let mut rep_params = ParamSet::new(data.key_len, data.sequences.len() / data.key_len);
              let prefix = format!("[{}]", rep);
              let ll = expectation_maximization(&data, &mut rep_params, 0.01, &prefix, aux);
              EMResult {
                  params: rep_params,
                  loglik: ll,
              }
          })
          .reduce_with(|params_a, params_b| {
              if params_a.loglik >= params_b.loglik {
                  params_a
              } else {
                  params_b
              }
          }).unwrap();
    if args.flag_verbose {
        println!("Final log likelihood: {:.5}", res.loglik);

        println!("");
        println!("EM pwm:");
        print_pwm(&res.params.alpha);
        println!("");
    }
    print_cutmask_table(&res.params.alpha, &data.mask);
}
